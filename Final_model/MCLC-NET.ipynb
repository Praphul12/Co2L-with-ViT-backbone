{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modality branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 40.3606\n",
      "Epoch [2/20], Loss: 10.4985\n",
      "Epoch [3/20], Loss: 4.4075\n",
      "Epoch [4/20], Loss: 3.5835\n",
      "Epoch [5/20], Loss: 3.0951\n",
      "Epoch [6/20], Loss: 0.3706\n",
      "Epoch [7/20], Loss: 7.7322\n",
      "Epoch [8/20], Loss: 1.3942\n",
      "Epoch [9/20], Loss: 6.2009\n",
      "Epoch [10/20], Loss: 1.1194\n",
      "Epoch [11/20], Loss: 1.0015\n",
      "Epoch [12/20], Loss: 0.9413\n",
      "Epoch [13/20], Loss: 0.5829\n",
      "Epoch [14/20], Loss: 1.5417\n",
      "Epoch [15/20], Loss: 0.3573\n",
      "Epoch [16/20], Loss: 1.5965\n",
      "Epoch [17/20], Loss: 2.8729\n",
      "Epoch [18/20], Loss: 2.6022\n",
      "Epoch [19/20], Loss: 1.0276\n",
      "Epoch [20/20], Loss: 2.9165\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class ModalityBranch(nn.Module):\n",
    "    def __init__(self, input_channels=3, name='modality'):\n",
    "        super(ModalityBranch, self).__init__()\n",
    "        self.name = name\n",
    "        # Use the updated method to load pretrained weights\n",
    "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        if input_channels != 3:\n",
    "            self.resnet.conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        self.fc = nn.Linear(2048, 1024)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, rgb_branch, depth_branch, thermal_branch):\n",
    "        super(MultiModalModel, self).__init__()\n",
    "        self.rgb_branch = rgb_branch\n",
    "        self.depth_branch = depth_branch\n",
    "        self.thermal_branch = thermal_branch\n",
    "        self.fusion = lambda x: torch.max(torch.stack(x), dim=0)[0] # Max pooling\n",
    "        # self.fusion = lambda x: torch.cat(x, dim=1)  # Concatenation instead of max pooling\n",
    "\n",
    "        self.regressor = nn.Linear(1024, 1)\n",
    "\n",
    "    def forward(self, rgb, depth, thermal):\n",
    "        rgb_features = self.rgb_branch(rgb)\n",
    "        depth_features = self.depth_branch(depth)\n",
    "        thermal_features = self.thermal_branch(thermal)\n",
    "        fused_features = self.fusion([rgb_features, depth_features, thermal_features])\n",
    "        output = self.regressor(fused_features)\n",
    "        return output\n",
    "\n",
    "class LeafCountingDataset(Dataset):\n",
    "    def __init__(self, csv_file, rgb_dir, depth_dir, thermal_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file, dtype={0: str})\n",
    "\n",
    "        self.rgb_dir = rgb_dir\n",
    "        self.depth_dir = depth_dir\n",
    "        self.thermal_dir = thermal_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_name = self.data.iloc[idx, 0].strip()\n",
    "            leaf_count = self.data.iloc[idx, 1]\n",
    "\n",
    "            rgb_path = os.path.join(self.rgb_dir, img_name + '.png')\n",
    "            depth_path = os.path.join(self.depth_dir, img_name + '_coldepth.png')\n",
    "            thermal_path = os.path.join(self.thermal_dir, img_name + '_coldepth.png' )\n",
    "\n",
    "            rgb_image = Image.open(rgb_path).convert('RGB')\n",
    "            depth_image = Image.open(depth_path).convert('L')\n",
    "            thermal_image = Image.open(thermal_path).convert('L')\n",
    "            \n",
    "            # depth_image = depth_image.convert('RGB')\n",
    "            # thermal_image = thermal_image.convert('RGB')\n",
    "\n",
    "            if self.transform:\n",
    "                rgb_image = self.transform(rgb_image)  # Apply transformations for 3-channel\n",
    "             # For depth and thermal, normalize them separately since they are single-channel images\n",
    "                depth_image = transforms.functional.to_tensor(depth_image)  # Convert to tensor (single-channel)\n",
    "                depth_image = transforms.functional.normalize(depth_image, mean=[0.5], std=[0.5])  # Normalize\n",
    "                thermal_image = transforms.functional.to_tensor(thermal_image)  # Convert to tensor (single-channel)\n",
    "                thermal_image = transforms.functional.normalize(thermal_image, mean=[0.5], std=[0.5])  # Normalize\n",
    "\n",
    "            return rgb_image, depth_image, thermal_image, torch.tensor(leaf_count, dtype=torch.float)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_name}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = LeafCountingDataset(\n",
    "    csv_file= r\"C:\\Users\\praph\\Downloads\\Bottlegourd_week3.csv.txt\",\n",
    "    rgb_dir= r\"C:\\Users\\praph\\Downloads\\week3_cropped_bottlegourd_RGB\",\n",
    "    depth_dir= r\"C:\\Users\\praph\\Downloads\\week3_cropped_coldepth\",\n",
    "    thermal_dir= r\"C:\\Users\\praph\\Downloads\\week3_cropped_coldepth\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "# Create model\n",
    "rgb_branch = ModalityBranch(input_channels=3, name='rgb')\n",
    "depth_branch = ModalityBranch(input_channels=1, name='depth')\n",
    "thermal_branch = ModalityBranch(input_channels=1, name='thermal')\n",
    "model = MultiModalModel(rgb_branch, depth_branch, thermal_branch)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for rgb, depth, thermal, leaf_count in dataloader:\n",
    "        rgb, depth, thermal, leaf_count = rgb.to(device), depth.to(device), thermal.to(device), leaf_count.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(rgb, depth, thermal)\n",
    "        loss = criterion(outputs.squeeze(), leaf_count)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Training finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modality branch only RGB and depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with learning rate: 0.0001\n",
      "Epoch [1/20], Loss: 57.9029, MSE: 57.9029, RMSE: 7.6086\n",
      "Epoch [2/20], Loss: 25.1433, MSE: 25.1433, RMSE: 4.9902\n",
      "Epoch [3/20], Loss: 11.5045, MSE: 11.5045, RMSE: 3.3912\n",
      "Epoch [4/20], Loss: 2.0233, MSE: 2.0233, RMSE: 1.4015\n",
      "Epoch [5/20], Loss: 2.1490, MSE: 2.1490, RMSE: 1.3077\n",
      "Epoch [6/20], Loss: 1.9933, MSE: 1.9933, RMSE: 1.4118\n",
      "Epoch [7/20], Loss: 2.2762, MSE: 2.2762, RMSE: 1.4501\n",
      "Epoch [8/20], Loss: 3.8416, MSE: 3.8416, RMSE: 1.9553\n",
      "Epoch [9/20], Loss: 3.6058, MSE: 3.6058, RMSE: 1.8504\n",
      "Epoch [10/20], Loss: 0.8533, MSE: 0.8533, RMSE: 0.8911\n",
      "Epoch [11/20], Loss: 1.1749, MSE: 1.1749, RMSE: 1.0680\n",
      "Epoch [12/20], Loss: 0.7717, MSE: 0.7717, RMSE: 0.8731\n",
      "Epoch [13/20], Loss: 1.0772, MSE: 1.0772, RMSE: 1.0096\n",
      "Epoch [14/20], Loss: 0.8428, MSE: 0.8428, RMSE: 0.9170\n",
      "Epoch [15/20], Loss: 0.6264, MSE: 0.6264, RMSE: 0.7834\n",
      "Epoch [16/20], Loss: 1.0613, MSE: 1.0613, RMSE: 0.9897\n",
      "Epoch [17/20], Loss: 0.5875, MSE: 0.5875, RMSE: 0.7471\n",
      "Epoch [18/20], Loss: 0.2179, MSE: 0.2179, RMSE: 0.4659\n",
      "Epoch [19/20], Loss: 3.1492, MSE: 3.1492, RMSE: 1.5289\n",
      "Epoch [20/20], Loss: 0.5421, MSE: 0.5421, RMSE: 0.7363\n",
      "\n",
      "Training with learning rate: 0.001\n",
      "Epoch [1/20], Loss: 37.7502, MSE: 37.7502, RMSE: 5.0720\n",
      "Epoch [2/20], Loss: 19.3824, MSE: 19.3824, RMSE: 4.3896\n",
      "Epoch [3/20], Loss: 4.2539, MSE: 4.2539, RMSE: 2.0622\n",
      "Epoch [4/20], Loss: 5.5870, MSE: 5.5870, RMSE: 2.3065\n",
      "Epoch [5/20], Loss: 4.8351, MSE: 4.8351, RMSE: 2.1944\n",
      "Epoch [6/20], Loss: 2.3114, MSE: 2.3114, RMSE: 1.4966\n",
      "Epoch [7/20], Loss: 2.1490, MSE: 2.1490, RMSE: 1.4245\n",
      "Epoch [8/20], Loss: 1.7204, MSE: 1.7204, RMSE: 1.3105\n",
      "Epoch [9/20], Loss: 2.3879, MSE: 2.3879, RMSE: 1.5440\n",
      "Epoch [10/20], Loss: 3.8970, MSE: 3.8970, RMSE: 1.8930\n",
      "Epoch [11/20], Loss: 2.3983, MSE: 2.3983, RMSE: 1.5248\n",
      "Epoch [12/20], Loss: 4.3581, MSE: 4.3581, RMSE: 2.0228\n",
      "Epoch [13/20], Loss: 1.6426, MSE: 1.6426, RMSE: 1.2442\n",
      "Epoch [14/20], Loss: 2.5250, MSE: 2.5250, RMSE: 1.5448\n",
      "Epoch [15/20], Loss: 1.3884, MSE: 1.3884, RMSE: 1.0886\n",
      "Epoch [16/20], Loss: 1.4881, MSE: 1.4881, RMSE: 1.1795\n",
      "Epoch [17/20], Loss: 0.9892, MSE: 0.9892, RMSE: 0.9938\n",
      "Epoch [18/20], Loss: 0.5317, MSE: 0.5317, RMSE: 0.7257\n",
      "Epoch [19/20], Loss: 1.0551, MSE: 1.0551, RMSE: 0.9599\n",
      "Epoch [20/20], Loss: 1.2640, MSE: 1.2640, RMSE: 1.1183\n",
      "\n",
      "Training with learning rate: 0.01\n",
      "Epoch [1/20], Loss: 589.8573, MSE: 589.8573, RMSE: 20.6553\n",
      "Epoch [2/20], Loss: 22.8346, MSE: 22.8346, RMSE: 4.6065\n",
      "Epoch [3/20], Loss: 30.1756, MSE: 30.1756, RMSE: 5.2966\n",
      "Epoch [4/20], Loss: 18.5044, MSE: 18.5044, RMSE: 3.9666\n",
      "Epoch [5/20], Loss: 8.3322, MSE: 8.3322, RMSE: 2.8766\n",
      "Epoch [6/20], Loss: 11.5209, MSE: 11.5209, RMSE: 3.3823\n",
      "Epoch [7/20], Loss: 8.0465, MSE: 8.0465, RMSE: 2.6540\n",
      "Epoch [8/20], Loss: 14.4702, MSE: 14.4702, RMSE: 3.7795\n",
      "Epoch [9/20], Loss: 6.4295, MSE: 6.4295, RMSE: 2.5043\n",
      "Epoch [10/20], Loss: 4.1778, MSE: 4.1778, RMSE: 2.0410\n",
      "Epoch [11/20], Loss: 4.9706, MSE: 4.9706, RMSE: 2.2014\n",
      "Epoch [12/20], Loss: 5.1252, MSE: 5.1252, RMSE: 2.2632\n",
      "Epoch [13/20], Loss: 2.7220, MSE: 2.7220, RMSE: 1.4159\n",
      "Epoch [14/20], Loss: 2.7697, MSE: 2.7697, RMSE: 1.6480\n",
      "Epoch [15/20], Loss: 2.2850, MSE: 2.2850, RMSE: 1.4159\n",
      "Epoch [16/20], Loss: 3.5720, MSE: 3.5720, RMSE: 1.8898\n",
      "Epoch [17/20], Loss: 2.3861, MSE: 2.3861, RMSE: 1.5349\n",
      "Epoch [18/20], Loss: 2.6604, MSE: 2.6604, RMSE: 1.6307\n",
      "Epoch [19/20], Loss: 9.2108, MSE: 9.2108, RMSE: 2.9158\n",
      "Epoch [20/20], Loss: 8.3082, MSE: 8.3082, RMSE: 2.8438\n",
      "\n",
      "Training with learning rate: 0.1\n",
      "Epoch [1/20], Loss: 1090.6216, MSE: 1090.6216, RMSE: 28.3321\n",
      "Epoch [2/20], Loss: 201.5213, MSE: 201.5213, RMSE: 14.1956\n",
      "Epoch [3/20], Loss: 264.5027, MSE: 264.5027, RMSE: 14.7391\n",
      "Epoch [4/20], Loss: 281.1514, MSE: 281.1514, RMSE: 16.3019\n",
      "Epoch [5/20], Loss: 172.1025, MSE: 172.1025, RMSE: 11.8624\n",
      "Epoch [6/20], Loss: 37.2869, MSE: 37.2869, RMSE: 6.0915\n",
      "Epoch [7/20], Loss: 21.3695, MSE: 21.3695, RMSE: 4.2304\n",
      "Epoch [8/20], Loss: 73.7353, MSE: 73.7353, RMSE: 7.4274\n",
      "Epoch [9/20], Loss: 40.5014, MSE: 40.5014, RMSE: 5.2916\n",
      "Epoch [10/20], Loss: 42.4768, MSE: 42.4768, RMSE: 6.4240\n",
      "Epoch [11/20], Loss: 6.7063, MSE: 6.7063, RMSE: 2.2229\n",
      "Epoch [12/20], Loss: 18.9686, MSE: 18.9686, RMSE: 3.9999\n",
      "Epoch [13/20], Loss: 9.2662, MSE: 9.2662, RMSE: 3.0241\n",
      "Epoch [14/20], Loss: 3.7664, MSE: 3.7664, RMSE: 1.9125\n",
      "Epoch [15/20], Loss: 2.1647, MSE: 2.1647, RMSE: 1.4248\n",
      "Epoch [16/20], Loss: 2.2023, MSE: 2.2023, RMSE: 1.4608\n",
      "Epoch [17/20], Loss: 5.7934, MSE: 5.7934, RMSE: 2.0287\n",
      "Epoch [18/20], Loss: 4.2465, MSE: 4.2465, RMSE: 2.0072\n",
      "Epoch [19/20], Loss: 2.1043, MSE: 2.1043, RMSE: 1.4089\n",
      "Epoch [20/20], Loss: 3.0858, MSE: 3.0858, RMSE: 1.7556\n",
      "Training finished for all learning rates!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "class ModalityBranch(nn.Module):\n",
    "    def __init__(self, input_channels=3, name='modality'):\n",
    "        super(ModalityBranch, self).__init__()\n",
    "        self.name = name\n",
    "        # Use the updated method to load pretrained weights\n",
    "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        if input_channels != 3:\n",
    "            self.resnet.conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        self.fc = nn.Linear(2048, 1024)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, rgb_branch, depth_branch):\n",
    "        super(MultiModalModel, self).__init__()\n",
    "        self.rgb_branch = rgb_branch\n",
    "        self.depth_branch = depth_branch\n",
    "        self.fusion = lambda x: torch.max(torch.stack(x), dim=0)[0]  # Max pooling\n",
    "\n",
    "        self.regressor = nn.Linear(1024, 1)\n",
    "\n",
    "    def forward(self, rgb, depth):\n",
    "        rgb_features = self.rgb_branch(rgb)\n",
    "        depth_features = self.depth_branch(depth)\n",
    "        fused_features = self.fusion([rgb_features, depth_features])\n",
    "        output = self.regressor(fused_features)\n",
    "        return output\n",
    "\n",
    "class LeafCountingDataset(Dataset):\n",
    "    def __init__(self, csv_file, rgb_dir, depth_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file, dtype={0: str})\n",
    "        self.rgb_dir = rgb_dir\n",
    "        self.depth_dir = depth_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_name = self.data.iloc[idx, 0].strip()\n",
    "            leaf_count = self.data.iloc[idx, 1]\n",
    "\n",
    "            rgb_path = os.path.join(self.rgb_dir, img_name + '.png')\n",
    "            depth_path = os.path.join(self.depth_dir, img_name + '_coldepth.png')\n",
    "\n",
    "            rgb_image = Image.open(rgb_path).convert('RGB')\n",
    "            depth_image = Image.open(depth_path).convert('L')\n",
    "\n",
    "            if self.transform:\n",
    "                rgb_image = self.transform(rgb_image)  # Apply transformations for RGB (3-channel)\n",
    "                depth_image = transforms.functional.to_tensor(depth_image)  # Convert to tensor (single-channel)\n",
    "                depth_image = transforms.functional.normalize(depth_image, mean=[0.5], std=[0.5])  # Normalize\n",
    "\n",
    "            return rgb_image, depth_image, torch.tensor(leaf_count, dtype=torch.float)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_name}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = LeafCountingDataset(\n",
    "    csv_file= r\"C:\\Users\\praph\\Downloads\\Bottlegourd_week3.csv.txt\",\n",
    "    rgb_dir= r\"C:\\Users\\praph\\Downloads\\week3_cropped_bottlegourd_RGB\",\n",
    "    depth_dir= r\"C:\\Users\\praph\\Downloads\\week3_cropped_coldepth\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "# Create model\n",
    "rgb_branch = ModalityBranch(input_channels=3, name='rgb')\n",
    "depth_branch = ModalityBranch(input_channels=1, name='depth')\n",
    "model = MultiModalModel(rgb_branch, depth_branch)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Function to calculate MSE and RMSE\n",
    "def calculate_metrics(true, predicted):\n",
    "    mse = criterion(predicted, true).item()\n",
    "    rmse = math.sqrt(mse)\n",
    "    return mse, rmse\n",
    "\n",
    "# Training function\n",
    "def train_model(model, dataloader, learning_rate, num_epochs=20):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        mse_epoch = 0.0\n",
    "        rmse_epoch = 0.0\n",
    "        count = 0\n",
    "        \n",
    "        for rgb, depth, leaf_count in dataloader:\n",
    "            rgb, depth, leaf_count = rgb.to(device), depth.to(device), leaf_count.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(rgb, depth)\n",
    "            loss = criterion(outputs.squeeze(), leaf_count)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            mse, rmse = calculate_metrics(leaf_count, outputs.squeeze())\n",
    "            mse_epoch += mse\n",
    "            rmse_epoch += rmse\n",
    "            count += 1\n",
    "\n",
    "        avg_loss = epoch_loss / count\n",
    "        avg_mse = mse_epoch / count\n",
    "        avg_rmse = rmse_epoch / count\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, MSE: {avg_mse:.4f}, RMSE: {avg_rmse:.4f}')\n",
    "\n",
    "# Training for different learning rates\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
    "num_epochs = 20\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nTraining with learning rate: {lr}\")\n",
    "    model = MultiModalModel(rgb_branch, depth_branch)  # Reinitialize the model for each run\n",
    "    train_model(model, dataloader, learning_rate=lr, num_epochs=num_epochs)\n",
    "\n",
    "print('Training finished for all learning rates!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 54.3683\n",
      "Epoch [2/20], Loss: 23.1539\n",
      "Epoch [3/20], Loss: 20.1985\n",
      "Epoch [4/20], Loss: 10.7420\n",
      "Epoch [5/20], Loss: 1.2113\n",
      "Epoch [6/20], Loss: 0.4133\n",
      "Epoch [7/20], Loss: 0.2341\n",
      "Epoch [8/20], Loss: 1.3959\n",
      "Epoch [9/20], Loss: 9.6384\n",
      "Epoch [10/20], Loss: 5.6913\n",
      "Epoch [11/20], Loss: 1.7998\n",
      "Epoch [12/20], Loss: 1.6266\n",
      "Epoch [13/20], Loss: 0.3446\n",
      "Epoch [14/20], Loss: 0.4447\n",
      "Epoch [15/20], Loss: 1.0181\n",
      "Epoch [16/20], Loss: 1.5610\n",
      "Epoch [17/20], Loss: 2.0285\n",
      "Epoch [18/20], Loss: 0.8952\n",
      "Epoch [19/20], Loss: 1.0157\n",
      "Epoch [20/20], Loss: 2.7328\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# RGB Branch Only\n",
    "class RGBBranch(nn.Module):\n",
    "    def __init__(self, input_channels=3, name='rgb'):\n",
    "        super(RGBBranch, self).__init__()\n",
    "        self.name = name\n",
    "        # Load pretrained resnet50 model\n",
    "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        if input_channels != 3:\n",
    "            self.resnet.conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        self.fc = nn.Linear(2048, 1024)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "# Modified model to use only RGB branch\n",
    "class LeafCountingModel(nn.Module):\n",
    "    def __init__(self, rgb_branch):\n",
    "        super(LeafCountingModel, self).__init__()\n",
    "        self.rgb_branch = rgb_branch\n",
    "        self.regressor = nn.Linear(1024, 1)\n",
    "\n",
    "    def forward(self, rgb):\n",
    "        rgb_features = self.rgb_branch(rgb)\n",
    "        output = self.regressor(rgb_features)\n",
    "        return output\n",
    "\n",
    "# Dataset class (only RGB images now)\n",
    "class LeafCountingDataset(Dataset):\n",
    "    def __init__(self, csv_file, rgb_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file, dtype={0: str})\n",
    "        self.rgb_dir = rgb_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_name = self.data.iloc[idx, 0].strip()  # Image name\n",
    "            leaf_count = self.data.iloc[idx, 1]  # Leaf count\n",
    "\n",
    "            rgb_path = os.path.join(self.rgb_dir, img_name + '.png')\n",
    "            rgb_image = Image.open(rgb_path).convert('RGB')\n",
    "\n",
    "            if self.transform:\n",
    "                rgb_image = self.transform(rgb_image)  # Apply transformations for RGB\n",
    "\n",
    "            return rgb_image, torch.tensor(leaf_count, dtype=torch.float)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_name}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = LeafCountingDataset(\n",
    "    csv_file= r\"C:\\Users\\praph\\Downloads\\Bottlegourd_week3.csv.txt\",\n",
    "    rgb_dir= r\"C:\\Users\\praph\\Downloads\\week3_cropped_bottlegourd_RGB\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "# Create model (RGB branch only)\n",
    "rgb_branch = RGBBranch(input_channels=3, name='rgb')\n",
    "model = LeafCountingModel(rgb_branch)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for rgb, leaf_count in dataloader:\n",
    "        rgb, leaf_count = rgb.to(device), leaf_count.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(rgb)\n",
    "        loss = criterion(outputs.squeeze(), leaf_count)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Training finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
